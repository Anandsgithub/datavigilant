# üó∫ Anand's Portfolio

I am a resourceful professional with diverse experience in data, I possess a strong background in Python and R for programming, proficiency in SQL, DB2, Oracle, and Snowflake for database management, and expertise in ETL processes using Informatica Power Center 9.1x. Skilled in data visualization with Power BI, I have streamlined data processing and reporting, significantly enhancing data retrieval efficiency across various industries. I am adept at translating complex data into actionable business insights.

## üìö Table of Contents
- [Python](#python)
- [Informatica](#informatica)
- [SQL](#sql)
- [Unix](#unix)
- [Power BI](#powerbi)


# Data Science
| Project Topic | Completion Date | Tools | Project Description | 
|---|---|---|---|
| Did countries with access to traditional financial services lacking digital access experience more COVID-19 cases? | Feb 2024 | Python, Tableau,  Web Scraping on Jupyter Notebook. | This project investigates the correlation between access to traditional financial services and the impact of COVID-19. By analyzing data from various countries, the project aims to understand whether the lack of digital financial services contributed to higher COVID-19 cases. |
| Data Activism for the Christchurch Community | Sep 2023 |Python, SQL,  Tableau | This project focuses on important events and festivals within the Christchurch Muslim community. It aims to organize events based on traffic, weather, and other data to ensure smooth and successful gatherings. |
| A Data Science Dive into Chess Strategy
This project blends chess intelligence with data science to extract real strategic insights from online games √¢‚Ç¨‚Äù perfect for chess lovers and data enthusiasts alike.

Project Highlights
Real-Time Game Extraction
Fetches the 50 latest rated games of any Lichess user, including opening data.
Stores data in NDJSON format and performs integrity checks to ensure clean, usable input.

Data Transformation & Feature Engineering
Parses game data into a structured pandas DataFrame.
Extracts opening names, ECO codes, player ratings, and match results.
Handles missing values and formats outcomes for accurate analysis.

Opening Performance Analytics
Calculates win rates by opening for both White and Black.
Highlights the Top 10 openings by win rate.
Visualized with Seaborn bar charts for intuitive comparisons.

Move Pattern & Piece Activity Analysis
Parses PGN move strings to quantify how often each piece is moved.
Calculates average piece activity and visualizes relationships using heatmaps.

Interactive Streamlit Dashboard
An intuitive web interface to explore opening performance and piece activity.
Includes interactive charts and key strategic stats.

Simulated Strategic Metrics (Sample Data)
Simulates and visualizes:
Win rate by opening
Average piece development
Center control influence
Piece activity levels
Castling speed (king safety)

Visual Chess Insights
Uses Matplotlib to model pawn structures, central control, and chain formations.
Generates heatmaps and descriptive statistics for all core metrics.

Tech Stack & Tools
Languages: Python
Libraries: pandas, numpy, seaborn, matplotlib, streamlit, requests, python-chess, json
Techniques: NDJSON parsing, PGN analysis, data cleaning, statistical modeling, simulation, visual storytelling |

***
# ETL
| Project Topic | Project Description | Tools |
|---|---|---|
| Combining Data from Multiple Provider Sources into EPDSV2 | This project involved integrating data from various provider sources into a single repository called EPDSV2. Providers are stored in Oracle, sourced from Mainframe DB2. The provider records are then sent to downstream systems for further processing or changes. This comprehensive ETL process ensures data accuracy and consistency across multiple platforms. | Informatica, Oracle, Mainframe DB2| 
| Migrating Data from New Business into EPDSV2 | This project involves migrating data from various new business sources into a single repository called EPDSV2. The data from providers is stored in Teradata, sourced from Mainframe DB2, IMS DB, SQL, Snowflake, and Oracle. The provider records are then processed in UNIX and Shell environments for further downstream processing or changes. This comprehensive ETL process ensures data accuracy and consistency across multiple platforms. | Informatica, Teradata, Mainframe DB2, IMS DB, SQL, Snowflake, Oracle, UNIX, Shell, Power BI |  
| Automating Data Extraction and Transformation | This project focuses on automating the entire ETL process, eliminating the need for human intervention. Data extraction and transformation are performed seamlessly across multiple sources, and an email notification is triggered upon process completion. The aim is to enhance efficiency, accuracy, and timeliness in data processing. | Python, UNIX, Shell, Automated Email Notifications, Power BI |  
***

# Mainframe
| Project Topic | Project Description | Tools |
|---|---|---|
| Healthcare Membership Enrollment Automation |This project focuses on automating the enrollment process for healthcare insurance memberships. Customers can enroll individually, as groups, or as families. All customer details are stored and processed through batch processing, ensuring efficient and accurate data handling. The system leverages mainframe technologies to streamline and automate legacy processes, reducing manual intervention and improving overall efficiency. | COBOL, EASYTRIEVE, DB2, VSAM, JCL, SPUFI, Endevor R4.0, Change man, Insync V2.7, FMIMS, JCL | 
| Anthem Health Rewards Program | This project focuses on developing and automating the enrollment process for Anthem Health Rewards, a program designed to incentivize healthy behaviors among members. Enrollment for Health Rewards: Seamlessly automates the enrollment process for Anthem Health Rewards System Integration: Integrates with multiple downstream systems for further data processing and updates. | COBOL, DB2, VSAM, JCL, SPUFI, Endevor R4.0, Change man, Insync V2.7, FMIMS, JCL, CA-7 |  
| Generating Reports for Unpaid Claims and Verifying Provider Details | This project focuses on generating comprehensive reports of providers with unpaid claims. It ensures that the billing process remains uninterrupted by verifying addresses and other demographic details. Data Verification: Implemented processes to verify provider addresses and demographic details. Error Handling: Developed robust error handling and logging mechanisms to ensure data integrity. System Integration: Integrated with existing billing systems to ensure seamless data flow. |  EASYTRIEVE, DB2, JCL |  
***

## Skillset
- Programming : Python, R, COBOL, EASYTRIEVE
- ETL Tool : Informatica 
- Scripting : Unix, Powershell
- Database : SQL, DB2, Oracle, Snowflake
- Data Visualisation : PowerBI, Tableau
- Cloud Platforms : AWS, Azure
- Version control : GIT
- Web technologies : HTML, CSS, JS, PHP
- Soft skills : Problem solving, Critical thinking, Communication
